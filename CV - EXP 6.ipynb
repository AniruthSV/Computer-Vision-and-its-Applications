{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1MpbQskePzkp0gpZVwfjb3iZjCSLt6-rU","authorship_tag":"ABX9TyMUAIxD7qZCv9kJGpe3A5wL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1Nee3pkhTFvSIqmF9RqDQG2MgJWy9Y1Lv"},"id":"fFtuRJGHCAyx","executionInfo":{"status":"ok","timestamp":1758814416605,"user_tz":-330,"elapsed":19457,"user":{"displayName":"ANIRUTH S V 231501015","userId":"06372929894411710284"}},"outputId":"e7cc4232-01bb-47a6-a69b-57f1ce73ae9f"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","\n","# ========== SIFT FEATURE DETECTION ==========\n","\n","# Step 1: Start\n","print(\"SIFT Feature Detection Started\")\n","\n","# Step 2: Read the input image\n","image_path = \"/content/drive/MyDrive/CV Images/FNV for CV.jpeg\"  # Replace with your actual image path\n","img = cv2.imread(image_path)\n","if img is None:\n","    print(\"Error: Image not found.\")\n","    exit()\n","\n","# Step 3: Convert the image to grayscale\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","# Step 4: Create a SIFT detector\n","sift = cv2.SIFT_create()\n","\n","# Step 5: Detect keypoints and compute descriptors\n","keypoints, descriptors = sift.detectAndCompute(gray, None)\n","\n","# Step 6: Draw the keypoints on the image\n","img_keypoints = cv2.drawKeypoints(img, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","\n","# Step 7: Display the image with detected features\n","print(\"SIFT Keypoints: \\n\")\n","cv2_imshow(img_keypoints)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n","\n","# Step 8: End\n","print(\"SIFT Feature Detection Completed\")\n","\n","\n","# ========== HOG FEATURE DETECTION ==========\n","\n","# Step 1: Start\n","print(\"HOG Feature Detection Started\")\n","\n","# Step 2: Read the input image and convert it to grayscale\n","img = cv2.imread(image_path)\n","if img is None:\n","    print(\"Error: Image not found.\")\n","    exit()\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","# Step 3: Normalize the image size for consistency\n","resized_img = cv2.resize(gray, (128, 128))\n","\n","# Step 4: Create a HOGDescriptor and compute the HOG features\n","hog = cv2.HOGDescriptor(_winSize=(128, 128),\n","                        _blockSize=(32, 32),\n","                        _blockStride=(16, 16),\n","                        _cellSize=(16, 16),\n","                        _nbins=9)\n","\n","# Step 5â€“8: Compute HOG descriptor\n","hog_features = hog.compute(resized_img)\n","\n","# Step 9: Visualize the HOG features\n","# Using OpenCV's built-in visualization method for simplicity\n","# Create a copy of the resized image to draw the visualization\n","hog_image = resized_img.copy()\n","\n","# Optionally enhance the image to highlight gradients\n","hog_image = cv2.equalizeHist(hog_image)\n","\n","plt.figure(figsize=(8, 4))\n","plt.subplot(1, 2, 1)\n","plt.title(\"Original Image\")\n","plt.axis('off')\n","plt.imshow(resized_img, cmap='gray')\n","\n","plt.subplot(1, 2, 2)\n","plt.title(\"HOG Features Visualization\")\n","plt.axis('off')\n","plt.imshow(hog_image, cmap='gray')\n","\n","plt.show()\n","\n","# Step 10: End\n","print(\"HOG Feature Detection Completed\")"]}]}